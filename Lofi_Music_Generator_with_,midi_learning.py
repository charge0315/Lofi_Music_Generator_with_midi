# ğŸµ Lofi Music Generator - å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚º
# MIDIãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã‚ŒãŸéŸ³æ¥½ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰LofiéŸ³æ¥½ã‚’ç”Ÿæˆã—ã¾ã™

#@title 1. ã€ç’°å¢ƒè¨­å®šã€‘å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
print("ğŸ¹ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’é–‹å§‹ã—ã¾ã™...")
!pip install -q pretty_midi
!pip install -q tensorflow
!pip install -q music21
!pip install -q pydub
!pip install -q mido
print("âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

#@title 2. ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿ã€‘å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
print("ğŸ“š å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import pretty_midi
import pickle
import glob
from typing import List, Tuple
import random
from IPython.display import Audio, display
import matplotlib.pyplot as plt
from google.colab import drive
import zipfile
import requests
from tqdm import tqdm
from pydub import AudioSegment
from pydub.generators import Sine
import warnings
warnings.filterwarnings('ignore')
print("âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

#@title 3. ã€Google Driveé€£æºã€‘ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨
print("ğŸ’¾ Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¦ã„ã¾ã™...")
drive.mount('/content/drive')

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
work_dir = '/content/drive/MyDrive/LofiMusicGenerator'
os.makedirs(work_dir, exist_ok=True)
os.makedirs(f'{work_dir}/models', exist_ok=True)
os.makedirs(f'{work_dir}/generated_music', exist_ok=True)
os.makedirs(f'{work_dir}/datasets', exist_ok=True)
print(f"âœ… ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {work_dir}")

#@title 4. ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™ã€‘è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
print("ğŸ¼ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™...")

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š
datasets_config = {
    'maestro': {
        'name': 'MAESTROãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆã‚¯ãƒ©ã‚·ãƒƒã‚¯ãƒ”ã‚¢ãƒï¼‰',
        'url': 'https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip',
        'use_all': False,  # False: 100ä»¶, True: å…¨ä»¶
        'max_files': 100
    },
    'lmd': {
        'name': 'Lakh MIDI Datasetï¼ˆå¤šã‚¸ãƒ£ãƒ³ãƒ«ï¼‰',
        'url': 'http://hog.ee.columbia.edu/craffel/lmd/lmd_matched.tar.gz',
        'use_all': False,  # False: 100ä»¶, True: å…¨ä»¶
        'max_files': 100
    }
}

# ã©ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã‹é¸æŠ
print("\nğŸ“Š ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„:")
print("  1: MAESTROã®ã¿ï¼ˆã‚¯ãƒ©ã‚·ãƒƒã‚¯ãƒ”ã‚¢ãƒï¼‰")
print("  2: LMDã®ã¿ï¼ˆå¤šã‚¸ãƒ£ãƒ³ãƒ«ï¼‰")
print("  3: ä¸¡æ–¹ï¼ˆæ¨å¥¨ï¼‰")
dataset_choice = input("é¸æŠ (1/2/3, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1): ").strip()

if dataset_choice == '2':
    active_datasets = ['lmd']
elif dataset_choice == '3':
    active_datasets = ['maestro', 'lmd']
else:
    active_datasets = ['maestro']

print(f"\nâœ… é¸æŠã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {', '.join(active_datasets)}")

# å…¨ä»¶ä½¿ç”¨ã™ã‚‹ã‹ç¢ºèª
use_all = input("å…¨ä»¶ä½¿ç”¨ã—ã¾ã™ã‹ï¼Ÿ (y/n, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: n): ").strip().lower() == 'y'
if use_all:
    print("  âš ï¸ å…¨ä»¶ä½¿ç”¨ï¼šå‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™")
    for key in datasets_config:
        datasets_config[key]['use_all'] = True
        datasets_config[key]['max_files'] = None

all_midi_files = []

# MAESTROãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
if 'maestro' in active_datasets:
    print(f"\nğŸ“¥ {datasets_config['maestro']['name']}ã‚’æº–å‚™ä¸­...")
    maestro_path = f'{work_dir}/datasets/maestro'
    os.makedirs(maestro_path, exist_ok=True)
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
    maestro_files = glob.glob(f"{maestro_path}/**/*.mid*", recursive=True)
    
    if len(maestro_files) == 0:
        print("  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        response = requests.get(datasets_config['maestro']['url'], stream=True)
        total_size = int(response.headers.get('content-length', 0))
        
        zip_path = f'{maestro_path}/maestro.zip'
        with open(zip_path, 'wb') as file:
            with tqdm(total=total_size, unit='B', unit_scale=True, desc="MAESTRO") as pbar:
                for data in response.iter_content(chunk_size=8192):
                    file.write(data)
                    pbar.update(len(data))
        
        print("  è§£å‡ä¸­...")
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(maestro_path)
        os.remove(zip_path)
        
        maestro_files = glob.glob(f"{maestro_path}/**/*.mid*", recursive=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«æ•°åˆ¶é™
    if not datasets_config['maestro']['use_all']:
        maestro_files = maestro_files[:datasets_config['maestro']['max_files']]
    
    all_midi_files.extend(maestro_files)
    print(f"  âœ… MAESTRO: {len(maestro_files)}å€‹ã®MIDIãƒ•ã‚¡ã‚¤ãƒ«")

# Lakh MIDI Dataset
if 'lmd' in active_datasets:
    print(f"\nğŸ“¥ {datasets_config['lmd']['name']}ã‚’æº–å‚™ä¸­...")
    lmd_path = f'{work_dir}/datasets/lmd'
    os.makedirs(lmd_path, exist_ok=True)
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯
    lmd_files = glob.glob(f"{lmd_path}/**/*.mid*", recursive=True)
    
    if len(lmd_files) == 0:
        print("  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ï¼ˆç´„500MBï¼‰...")
        import tarfile
        
        response = requests.get(datasets_config['lmd']['url'], stream=True)
        total_size = int(response.headers.get('content-length', 0))
        
        tar_path = f'{lmd_path}/lmd.tar.gz'
        with open(tar_path, 'wb') as file:
            with tqdm(total=total_size, unit='B', unit_scale=True, desc="LMD") as pbar:
                for data in response.iter_content(chunk_size=8192):
                    file.write(data)
                    pbar.update(len(data))
        
        print("  è§£å‡ä¸­...")
        with tarfile.open(tar_path, 'r:gz') as tar_ref:
            tar_ref.extractall(lmd_path)
        os.remove(tar_path)
        
        lmd_files = glob.glob(f"{lmd_path}/**/*.mid*", recursive=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«æ•°åˆ¶é™
    if not datasets_config['lmd']['use_all']:
        # ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠï¼ˆå¤šæ§˜æ€§ã‚’ç¢ºä¿ï¼‰
        import random
        random.shuffle(lmd_files)
        lmd_files = lmd_files[:datasets_config['lmd']['max_files']]
    
    all_midi_files.extend(lmd_files)
    print(f"  âœ… LMD: {len(lmd_files)}å€‹ã®MIDIãƒ•ã‚¡ã‚¤ãƒ«")

# æœ€çµ‚ç¢ºèª
print(f"\nâœ… åˆè¨ˆ {len(all_midi_files)}å€‹ã®MIDIãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†å¯¾è±¡ã«ã—ã¾ã™")
midi_files = all_midi_files

#@title 5. ã€ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã€‘MIDIãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›
print("ğŸ”§ MIDIãƒ•ã‚¡ã‚¤ãƒ«ã®å‰å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")

class MIDIProcessor:
    """MIDIãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›"""
    
    def __init__(self, sequence_length: int = 256):
        self.sequence_length = sequence_length
        self.vocab_size = 388  # ãƒ”ãƒƒãƒ(128) + ãƒ™ãƒ­ã‚·ãƒ†ã‚£(32) + æ™‚é–“(100) + ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³(128)
        
    def midi_to_notes(self, midi_file: str) -> List[Tuple[int, int, float, float]]:
        """MIDIãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ¼ãƒˆã®ãƒªã‚¹ãƒˆã«å¤‰æ›"""
        try:
            pm = pretty_midi.PrettyMIDI(midi_file)
            notes = []
            
            for instrument in pm.instruments:
                if not instrument.is_drum:  # ãƒ‰ãƒ©ãƒ ãƒˆãƒ©ãƒƒã‚¯ã¯é™¤å¤–
                    for note in instrument.notes:
                        notes.append((
                            note.pitch,
                            note.velocity,
                            note.start,
                            note.end - note.start  # duration
                        ))
            
            # æ™‚é–“é †ã«ã‚½ãƒ¼ãƒˆ
            notes.sort(key=lambda x: x[2])
            return notes
        except Exception as e:
            return []
    
    def notes_to_sequence(self, notes: List[Tuple]) -> np.ndarray:
        """ãƒãƒ¼ãƒˆãƒªã‚¹ãƒˆã‚’æ•°å€¤ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¤‰æ›"""
        sequence = []
        
        for pitch, velocity, start, duration in notes:
            # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
            pitch_token = min(pitch, 127)
            velocity_token = min(velocity // 4, 31) + 128
            time_token = min(int(start * 10), 99) + 160
            duration_token = min(int(duration * 10), 99) + 260
            
            sequence.extend([pitch_token, velocity_token, time_token, duration_token])
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã¾ãŸã¯ãƒˆãƒªãƒŸãƒ³ã‚°
        if len(sequence) < self.sequence_length:
            sequence.extend([0] * (self.sequence_length - len(sequence)))
        else:
            sequence = sequence[:self.sequence_length]
        
        return np.array(sequence, dtype=np.int32)

# ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
processor = MIDIProcessor(sequence_length=256)

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã”ã¨ã«å‡¦ç†
sequences_by_dataset = {}
total_sequences = []

# MAESTROã®å‡¦ç†
maestro_sequences = []
if 'maestro' in active_datasets:
    maestro_files = [f for f in midi_files if 'maestro' in f]
    if maestro_files:
        print(f"\n  ğŸ¹ MAESTRO: {len(maestro_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­...")
        for midi_file in tqdm(maestro_files, desc="MAESTROå‡¦ç†"):
            notes = processor.midi_to_notes(midi_file)
            if notes:
                sequence = processor.notes_to_sequence(notes)
                maestro_sequences.append(sequence)
        
        sequences_by_dataset['maestro'] = np.array(maestro_sequences)
        total_sequences.extend(maestro_sequences)
        print(f"    âœ… {len(maestro_sequences)}å€‹ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆ")

# LMDã®å‡¦ç†
lmd_sequences = []
if 'lmd' in active_datasets:
    lmd_files = [f for f in midi_files if 'lmd' in f]
    if lmd_files:
        print(f"\n  ğŸµ LMD: {len(lmd_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­...")
        for midi_file in tqdm(lmd_files, desc="LMDå‡¦ç†"):
            notes = processor.midi_to_notes(midi_file)
            if notes and len(notes) > 10:  # çŸ­ã™ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯é™¤å¤–
                sequence = processor.notes_to_sequence(notes)
                lmd_sequences.append(sequence)
        
        sequences_by_dataset['lmd'] = np.array(lmd_sequences)
        total_sequences.extend(lmd_sequences)
        print(f"    âœ… {len(lmd_sequences)}å€‹ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆ")

# å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
X_train = np.array(total_sequences) if total_sequences else np.random.randint(0, processor.vocab_size, size=(100, 256))

print(f"\nâœ… å‰å‡¦ç†å®Œäº†ï¼")
print(f"  ç·ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ•°: {len(X_train)}")
if sequences_by_dataset:
    for name, seqs in sequences_by_dataset.items():
        print(f"  - {name}: {len(seqs)}å€‹")

# ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆã®è­¦å‘Š
if len(X_train) < 50:
    print("\n  âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„ãŸã‚ã€å­¦ç¿’çµæœãŒä¸å®‰å®šã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    print("     ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™")

#@title 6. ã€Music Transformerã€‘ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
print("ğŸ¤– Music Transformerãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¦ã„ã¾ã™...")

class MusicTransformer(keras.Model):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªMusic Transformerãƒ¢ãƒ‡ãƒ«"""
    
    def __init__(self, vocab_size: int, d_model: int = 256):
        super().__init__()
        
        # åŸ‹ã‚è¾¼ã¿å±¤
        self.embedding = layers.Embedding(vocab_size, d_model)
        
        # LSTMå±¤ï¼ˆTransformerã®ç°¡æ˜“ç‰ˆã¨ã—ã¦ï¼‰
        self.lstm1 = layers.LSTM(d_model, return_sequences=True)
        self.lstm2 = layers.LSTM(d_model, return_sequences=True)
        self.dropout = layers.Dropout(0.2)
        
        # å‡ºåŠ›å±¤
        self.dense = layers.Dense(d_model, activation='relu')
        self.output_layer = layers.Dense(vocab_size, activation='softmax')
    
    def call(self, inputs, training=False):
        x = self.embedding(inputs)
        x = self.lstm1(x)
        x = self.dropout(x, training=training)
        x = self.lstm2(x)
        x = self.dropout(x, training=training)
        x = self.dense(x)
        return self.output_layer(x)

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
model = MusicTransformer(vocab_size=processor.vocab_size)

# ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print("âœ… ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

#@title 7. ã€å­¦ç¿’å®Ÿè¡Œã€‘ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
print("ğŸ¯ ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...")

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
X = X_train[:, :-1]
y = X_train[:, 1:]

# å­¦ç¿’ã®å®Ÿè¡Œï¼ˆã‚¨ãƒãƒƒã‚¯æ•°ã‚’å°‘ãªã‚ã«è¨­å®šï¼‰
print("  ğŸ“ˆ å­¦ç¿’ä¸­... (ã“ã‚Œã«ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)")
history = model.fit(
    X, y,
    batch_size=32,
    epochs=5,  # ãƒ‡ãƒ¢ç”¨ã«å°‘ãªã‚
    validation_split=0.1,
    verbose=1
)

# å­¦ç¿’æ›²ç·šã®è¡¨ç¤º
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
if 'val_loss' in history.history:
    plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss History')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
if 'val_accuracy' in history.history:
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy History')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

print("âœ… ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

#@title 8. ã€éŸ³æ¥½ç”Ÿæˆã€‘LofiéŸ³æ¥½ã‚’ç”Ÿæˆ
print("ğŸµ LofiéŸ³æ¥½ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")

def generate_music(model, processor, seed_sequence, length=512, temperature=0.8):
    """éŸ³æ¥½ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
    generated = list(seed_sequence)
    
    for _ in tqdm(range(length), desc="ç”Ÿæˆä¸­"):
        input_seq = np.array(generated[-255:]).reshape(1, -1)
        predictions = model.predict(input_seq, verbose=0)[0, -1, :]
        
        # temperatureé©ç”¨
        predictions = np.log(predictions + 1e-10) / temperature
        predictions = np.exp(predictions) / np.sum(np.exp(predictions))
        
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        predicted_token = np.random.choice(len(predictions), p=predictions)
        generated.append(predicted_token)
    
    return np.array(generated)

def sequence_to_midi(sequence, output_file, tempo=75):
    """ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’MIDIãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›"""
    pm = pretty_midi.PrettyMIDI(initial_tempo=tempo)
    piano = pretty_midi.Instrument(program=4)  # Electric Piano
    
    current_time = 0.0
    
    for i in range(0, len(sequence) - 3, 4):
        pitch = min(sequence[i], 127)
        velocity = min((sequence[i + 1] - 128) * 4, 127) if sequence[i + 1] >= 128 else 64
        start_time = (sequence[i + 2] - 160) * 0.1 if sequence[i + 2] >= 160 else current_time
        duration = (sequence[i + 3] - 260) * 0.1 if sequence[i + 3] >= 260 else 0.5
        
        if pitch > 0 and velocity > 0:
            note = pretty_midi.Note(
                velocity=velocity,
                pitch=pitch,
                start=start_time,
                end=start_time + duration
            )
            piano.notes.append(note)
            current_time = start_time + duration
    
    pm.instruments.append(piano)
    pm.write(output_file)
    return pm

# 3ã¤ã®ãƒˆãƒ©ãƒƒã‚¯ã‚’ç”Ÿæˆ
print("  ğŸ¹ 3ã¤ã®Lofiãƒˆãƒ©ãƒƒã‚¯ã‚’ç”Ÿæˆã—ã¾ã™...")

generated_files = []
for i in range(3):
    print(f"\n  ğŸµ ãƒˆãƒ©ãƒƒã‚¯ {i+1} ã‚’ç”Ÿæˆä¸­...")
    
    # ã‚·ãƒ¼ãƒ‰ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
    if len(X_train) > 0:
        seed_idx = np.random.randint(0, len(X_train))
        seed_sequence = X_train[seed_idx, :128]
    else:
        seed_sequence = np.random.randint(0, processor.vocab_size, size=128)
    
    # ç”Ÿæˆ
    temperature = 0.6 + i * 0.2
    generated_sequence = generate_music(model, processor, seed_sequence, length=256, temperature=temperature)
    
    # MIDIä¿å­˜
    midi_file = f"{work_dir}/generated_music/lofi_track_{i+1}.mid"
    pm = sequence_to_midi(generated_sequence, midi_file, tempo=70 + i * 5)
    generated_files.append(midi_file)
    
    print(f"  âœ… ãƒˆãƒ©ãƒƒã‚¯ {i+1} ç”Ÿæˆå®Œäº†ï¼")

print("\nâœ… LofiéŸ³æ¥½ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

#@title 9. ã€ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã€‘å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã‚’Google Driveã«ä¿å­˜
print("ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¦ã„ã¾ã™...")

# ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
model_path = f"{work_dir}/models/lofi_music_transformer.h5"
model.save(model_path)
print(f"  âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {model_path}")

# ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®è¨­å®šã‚‚ä¿å­˜
processor_config = {
    'sequence_length': processor.sequence_length,
    'vocab_size': processor.vocab_size
}

config_path = f"{work_dir}/models/processor_config.pkl"
with open(config_path, 'wb') as f:
    pickle.dump(processor_config, f)
print(f"  âœ… è¨­å®šä¿å­˜å®Œäº†: {config_path}")

#@title 10. ã€MP3ä¿å­˜ã€‘ç”Ÿæˆã—ãŸéŸ³æ¥½ã‚’MP3å½¢å¼ã§ä¿å­˜
print("ğŸ§ MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")

def midi_to_mp3(midi_file, mp3_file, duration=30):
    """MIDIã‚’ã‚·ãƒ³ãƒ—ãƒ«ãªMP3ã«å¤‰æ›ï¼ˆç°¡æ˜“ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼ï¼‰"""
    try:
        pm = pretty_midi.PrettyMIDI(midi_file)
        
        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
        sample_rate = 44100
        audio_length = int(min(duration, pm.get_end_time()) * sample_rate)
        audio = np.zeros(audio_length)
        
        for instrument in pm.instruments:
            for note in instrument.notes[:50]:  # æœ€åˆã®50ãƒãƒ¼ãƒˆã®ã¿
                start_sample = int(note.start * sample_rate)
                end_sample = min(int(note.end * sample_rate), audio_length)
                
                if start_sample < audio_length:
                    # å‘¨æ³¢æ•°è¨ˆç®—
                    frequency = 440.0 * (2.0 ** ((note.pitch - 69) / 12.0))
                    
                    # ã‚µã‚¤ãƒ³æ³¢ç”Ÿæˆ
                    t = np.arange(end_sample - start_sample) / sample_rate
                    wave = np.sin(2 * np.pi * frequency * t) * (note.velocity / 127.0) * 0.3
                    
                    # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã«è¿½åŠ 
                    end_idx = min(start_sample + len(wave), audio_length)
                    audio[start_sample:end_idx] += wave[:end_idx - start_sample]
        
        # æ­£è¦åŒ–
        if np.max(np.abs(audio)) > 0:
            audio = audio / np.max(np.abs(audio)) * 0.8
        
        # pydubã§å¤‰æ›
        audio_int16 = (audio * 32767).astype(np.int16)
        audio_segment = AudioSegment(
            audio_int16.tobytes(),
            frame_rate=sample_rate,
            sample_width=2,
            channels=1
        )
        
        # MP3ã¨ã—ã¦ä¿å­˜
        audio_segment.export(mp3_file, format="mp3", bitrate="192k")
        return True
        
    except Exception as e:
        print(f"  âš ï¸ MP3å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
        return False

# ç”Ÿæˆã—ãŸMIDIãƒ•ã‚¡ã‚¤ãƒ«ã‚’MP3ã«å¤‰æ›
mp3_files = []
for i, midi_file in enumerate(generated_files, 1):
    mp3_file = midi_file.replace('.mid', '.mp3')
    print(f"  ğŸµ ãƒˆãƒ©ãƒƒã‚¯ {i} ã‚’MP3ã«å¤‰æ›ä¸­...")
    
    if midi_to_mp3(midi_file, mp3_file, duration=30):
        mp3_files.append(mp3_file)
        print(f"  âœ… MP3ç”Ÿæˆå®Œäº†: {os.path.basename(mp3_file)}")
    else:
        print(f"  âš ï¸ MP3å¤‰æ›ã‚’ã‚¹ã‚­ãƒƒãƒ—")

print(f"\nâœ… {len(mp3_files)}å€‹ã®MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")

# å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
print("\n" + "="*60)
print("ğŸ‰ å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚ºãŒå®Œäº†ã—ã¾ã—ãŸï¼")
print("="*60)
print(f"\nğŸ“ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
print(f"  ãƒ¢ãƒ‡ãƒ«: {work_dir}/models/")
print(f"  éŸ³æ¥½: {work_dir}/generated_music/")
print("\nğŸ’¡ æ¬¡ã¯éŸ³æ¥½å†ç”Ÿãƒ•ã‚§ãƒ¼ã‚ºã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼")